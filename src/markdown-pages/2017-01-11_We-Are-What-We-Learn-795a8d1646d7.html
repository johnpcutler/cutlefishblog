<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>We Are What We Learn</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">We Are What We Learn</h1>
</header>
<section data-field="subtitle" class="p-summary">
When I talk to teams about data and evidence-driven product development, I invariably encounter some fear and trepidation:
</section>
<section data-field="body" class="e-content">
<section name="6399" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="df12" id="df12" class="graf graf--h3 graf--leading graf--title">We Are What We Learn</h3><p name="d4d3" id="d4d3" class="graf graf--p graf-after--h3">When I talk to teams about data and evidence-driven product development, I invariably encounter some fear and trepidation:</p><p name="46d7" id="46d7" class="graf graf--p graf--startsWithDoubleQuote graf-after--p">“What if we measure the wrong thing?”</p><p name="d18e" id="d18e" class="graf graf--p graf--startsWithDoubleQuote graf-after--p">“What if the data shows no one is using that feature?”</p><p name="9903" id="9903" class="graf graf--p graf--startsWithDoubleQuote graf-after--p">“I’m not sure I really trust their analysis. It’s oversimplified!”</p><p name="675c" id="675c" class="graf graf--p graf--startsWithDoubleQuote graf-after--p">“We don’t have the budget for a data scientist!”</p><p name="2388" id="2388" class="graf graf--p graf-after--p">But knowledge is power, right? What are we so afraid of? Plenty. Data can decide which initiatives are green-lighted or canned, which efforts have had an impact, whether to increase or decrease headcounts, when to fire customers, and when to pivot or proceed. This isn’t trivial stuff!</p><p name="46fc" id="46fc" class="graf graf--p graf-after--p">Sometimes fear holds us back from seeking data; other times efforts to use data never bear fruit. Not for lack of trying — plenty of companies invest massively in BI, analytics, data quality, eliminating data silos, etc. But somehow, this yields no new insights and no changes in direction. Somehow all prior assumptions and biases are confirmed, and it’s business as usual.</p><p name="9658" id="9658" class="graf graf--p graf-after--p">If there is one thing that the fear of data and failed attempts of data usage have in common, it is the use of data for management, rather than for learning.. These organizations miss the difference between instrumentation and new insights. With KPIs, performance is <em class="markup--em markup--p-em">indicated</em> and you’re checking conformance to a predetermined plan. Measurement in this case is used <em class="markup--em markup--p-em">as a management tool.</em></p><p name="4609" id="4609" class="graf graf--p graf-after--p">We’ve been told we are what we measure, and that we can’t manage what we can’t measure. I’d flip that a bit to say that we are what we learn. And if we need to learn something, we likely need to step out of the management-by-measurement mentality. Whatever it is, we don’t know it yet! To learn it, we need to be open to improvisation and experimentation. To quote H. Thomas Johnson, “Perhaps what you measure is what you get. More likely, what you measure is all you’ll get.”</p><p name="3c45" id="3c45" class="graf graf--p graf-after--p">Try asking yourself and your team these key questions:</p><ul class="postList"><li name="e0a7" id="e0a7" class="graf graf--li graf-after--p">What did we learn this month?</li><li name="3f8a" id="3f8a" class="graf graf--li graf-after--li">What must we learn more about next?</li><li name="4d3a" id="4d3a" class="graf graf--li graf-after--li">How should we try to learn about it?</li></ul><p name="d65e" id="d65e" class="graf graf--p graf-after--li">These question are asked far too infrequently compared to questions like “What’s the velocity,” “When will we finish,” “Is [person] performing,” and “Are we on target to hit the revenue goal?” The end result is that teams end up:</p><ul class="postList"><li name="eeba" id="eeba" class="graf graf--li graf-after--p">Not practicing, paralyzed by how to get started</li><li name="ad3b" id="ad3b" class="graf graf--li graf-after--li">Not exploring different methods and perspectives</li><li name="bc6e" id="bc6e" class="graf graf--li graf-after--li">Not addressing data quality issues for <em class="markup--em markup--li-em">new </em>areas of measurement</li><li name="2b0e" id="2b0e" class="graf graf--li graf-after--li">Not enjoying learning wins as a source of energy and buy-in</li></ul><p name="bccc" id="bccc" class="graf graf--p graf-after--li">You have to make learning a regular part of your work. To make this happen, I have found it helpful to convene a cross-functional learning team. Ideally this team should meet regularly (weekly or biweekly) to keep the momentum going. To make your learning team effective:</p><p name="8940" id="8940" class="graf graf--p graf-after--p">1. Form a team drawing from different parts of your organization. This is vital. By making this a team sport, you’re cross-pollinating learnings, methods, question framing skills and more. In addition to generating new learning, the goal is to leave everyone a bit more data-savvy and excited about learning with data.</p><p name="2535" id="2535" class="graf graf--p graf-after--p">2. Visualize a learning workflow (parallel to any ticketing systems or other project roadmaps) and make a commitment to moving your questions through it. Your best bet is to keep things conservative in terms of the amount of learning work in-progress. Below is a sample work flow. Note how I’ve divided in-progress questions into two potential workflows: one where the data is available and must be gathered and cleaned before analysis, and the other where some sort of experiment must be designed and run.</p><figure name="db56" id="db56" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 636px; max-height: 331px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 52%;"></div><img class="graf-image" data-image-id="1*hxVhIjIir7aUKi-8TiB1Tg.png" data-width="636" data-height="331" src="https://cdn-images-1.medium.com/max/800/1*hxVhIjIir7aUKi-8TiB1Tg.png"></div></figure><p name="02cd" id="02cd" class="graf graf--p graf-after--figure">3. Engage a data-savvy coach from inside your organization. Ideally you’ll have someone with a strong data science background to act as a coach and technical advisor. This analysis coach helps pair questions and learning goals with the appropriate analysis technique and provides learning resources to get people working through learning projects on their own. If the team or individual hits an impasse, the coach should help out, but the goal is to teach people how to fish.</p><p name="982e" id="982e" class="graf graf--p graf-after--p">4. Share the learnings inside and outside the learning team. Learning is contagious! Many teams forget what new insights feel like. They’re hyper-acclimated to thinking about measurement for management (and we HIT this goal) vs. measurement for learning. It’s also important to share your learnings on gathering your learnings. Reflect on the techniques you used and challenges you encountered (especially with access to data and data quality).</p><p name="ee71" id="ee71" class="graf graf--p graf-after--p graf--trailing">If your team feels anxious about data or your efforts at data-driven development fall flat, think about how you’re using data. What are you measuring and what are you learning? Learning is often overlooked, but crucial for real insights.</p></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@johnpcutler" class="p-author h-card">John Cutler</a> on <a href="https://medium.com/p/795a8d1646d7"><time class="dt-published" datetime="2017-01-11T05:43:46.063Z">January 11, 2017</time></a>.</p><p><a href="https://medium.com/@johnpcutler/we-are-what-we-learn-795a8d1646d7" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on July 22, 2019.</p></footer></article></body></html>