<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Dr. Obvious, Startup Validation, and Failure</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Dr. Obvious, Startup Validation, and Failure</h1>
</header>
<section data-field="subtitle" class="p-summary">
“Validating” your startup is a big buzz word lately. Heck, all you need is five minutes and a napkin. I think the term is misused.
</section>
<section data-field="body" class="e-content">
<section name="fa29" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="e45b" id="e45b" class="graf graf--h3 graf--leading graf--title">Dr. Obvious, Startup Validation, and Failure</h3><p name="8c5a" id="8c5a" class="graf graf--p graf--startsWithDoubleQuote graf-after--h3">“Validating” your startup is a big buzz word lately. Heck, <a href="http://www.inc.com/jessica-stillman/validate-your-startup-idea-in-5-minutes-or-less.html" data-href="http://www.inc.com/jessica-stillman/validate-your-startup-idea-in-5-minutes-or-less.html" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">all you need is five minutes and a napkin</a>. I think the term is misused.</p><p name="1aff" id="1aff" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Validation </strong>is doing tests for which you are trying to confirm some piece of information. <strong class="markup--strong markup--p-strong">Exploratory</strong> tests involve doing tests for which you gain value with both failures and successes. The difference is absolutely critical for startups. Simply validating commonly known information does little to produce privileged information. The real winners discover that twist: the UI that drives adoption, the untapped enterprise market, or the untested viral growth strategy. Why waste valuable resources on proving the known?</p><p name="2621" id="2621" class="graf graf--p graf-after--p">You are approaching validation (or what I prefer to call exploration) correctly if you get negative responses (failures) about 50% of the time. In the exploratory stage the most valuable learnings come with unexpected failures and unexpected successes.</p><p name="6f9b" id="6f9b" class="graf graf--p graf-after--p">Why? In <em class="markup--em markup--p-em">The Principles of Product Development Flow: Second Generation Lean Product Development</em>, Donald G. Reinertsen shows the following graph to demonstrate that the average information generated by such a test is a function of its failure rate:</p><figure name="7ccc" id="7ccc" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 383px; max-height: 397px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 103.69999999999999%;"></div><img class="graf-image" data-image-id="0*XRVALKugCEUqoy4O.jpg" data-width="383" data-height="397" src="https://cdn-images-1.medium.com/max/800/0*XRVALKugCEUqoy4O.jpg"></div></figure><p name="1f2a" id="1f2a" class="graf graf--p graf-after--figure">This should look familiar to engineers as the theoretical basis behind the binary search algorithm, but for the rest of us Reinertsen explains:</p><blockquote name="e903" id="e903" class="graf graf--blockquote graf-after--p">The equation in Figure 4–6 shows that the information content of a test comes from the degree of surprise associated with each possible result. Any unexpected success has high information content, as does any unexpected failure. Unfortunately, most companies do a far better job of communicating their successes than their failures. They carefully document successes, but fail to document failures. This can cause them to repeat the same failures. Repeating the same failures is waste, because it generates no new information. Only new failures generate information.</blockquote><p name="c4a2" id="c4a2" class="graf graf--p graf-after--blockquote">The takeaway? At first, do more exploring and less validating. You are attempting to purchase information, and to maximize the value of that information you must design tests that fail as often as they succeed.</p><p name="0e59" id="0e59" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Easy Test:</strong> “Hand entering those receipts must be pretty painful huh?”</p><p name="b656" id="b656" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Hard Test:</strong> “Will you sign a year long contract for $22,000 if I can solve that problem for you?”</p><p name="2754" id="2754" class="graf graf--p graf-after--p">If every interview confirms your core assumption(s), then you are likely asking the wrong questions, or you are simply eliciting “known” information that is shared broadly and not particularly valuable. Like drug companies you are looking to perform tests that have unexpected results driving asymmetric payoff functions — not simply validating what is known, or failing for failure’s sake.</p><p name="132e" id="132e" class="graf graf--p graf-after--p">For example, almost everyone finds taxes, losing weight, balancing your checkbook, and home buying painful. This is why there are such large industries around solving those problems. A company like <a href="https://www.mint.com/" data-href="https://www.mint.com/" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">Mint</a> didn’t need to validate that home budgeting was difficult. Rather, it needed to validate that you could disrupt with automation, bank relationships, take advantage of new bank APIs, and that there was a critical tipping point in terms of willingness to share financial data.</p><p name="d63c" id="d63c" class="graf graf--p graf-after--p">Some problems / pains are incredibly clear and poignant — they’ve been around for a long time — but the solution is elusive because you’ve got an “integration” problem. For example, take the music business. Everyone knew it was broken. Countless startups tried to address the problem. But it was Apple who side-stepped the integration / coordination problem.</p><p name="c17c" id="c17c" class="graf graf--p graf-after--p">Additionally, very few validation efforts take sufficient measures to avoid “leading the witness”. The <a href="http://en.wikipedia.org/wiki/Confirmation_bias" data-href="http://en.wikipedia.org/wiki/Confirmation_bias" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">confirmation bias</a> is in full effect, and we likely only hear what we want to hear. We are literally “validating” ourselves vs. figuring how where there is an angle for a business.</p><p name="4639" id="4639" class="graf graf--p graf-after--p graf--trailing">Most pain is known. The trick is timing, understanding sea changes in terms of user habits, unraveling integration issues to force disruption, and developing faster/cheaper ways to do things. Write some scripts, stop leading the witness, and make sure your interviews are challenging your assumptions as often as they are confirming your assumptions.</p></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@johnpcutler" class="p-author h-card">John Cutler</a> on <a href="https://medium.com/p/63709d1779ec"><time class="dt-published" datetime="2015-12-09T22:41:12.765Z">December 9, 2015</time></a>.</p><p><a href="https://medium.com/@johnpcutler/dr-obvious-startup-validation-and-failure-63709d1779ec" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on July 22, 2019.</p></footer></article></body></html>